{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9a6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9bede1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from memory_pair import MemoryPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97060104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------\n",
    "# helper: Sherman‚ÄìMorrison utilities\n",
    "def sm_add_inv(H_inv, u):\n",
    "    \"\"\"\n",
    "    Rank-1 *addition* :   H_new = H + u u·µÄ\n",
    "    Returns updated inverse H_inv_new.\n",
    "    \"\"\"\n",
    "    Hu = H_inv @ u\n",
    "    denom = 1.0 + u.T @ Hu\n",
    "    return H_inv - np.outer(Hu, Hu) / denom\n",
    "\n",
    "def sm_remove_inv(H_inv, u):\n",
    "    \"\"\"\n",
    "    Rank-1 *downdate* :   H_new = H ‚àí u u·µÄ\n",
    "    (caller must ensure denominator > 0)\n",
    "    \"\"\"\n",
    "    Hu = H_inv @ u\n",
    "    denom = 1.0 - u.T @ Hu           # must stay positive\n",
    "    return H_inv + np.outer(Hu, Hu) / denom\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "class StreamNewtonMemoryPair:\n",
    "    \"\"\"\n",
    "    Online ridge-regression learner + unlearner with\n",
    "    (Œµ,Œ¥)-style Gaussian noise per deletion.\n",
    "\n",
    "    Loss      : ¬Ω(Œ∏·µÄx ‚àí y)¬≤   (squared error)\n",
    "    Regulariser: Œª‚ÄñŒ∏‚Äñ‚ÇÇ¬≤\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, lam=1.0,\n",
    "                 eps_total=1.0,   delta_total=1e-5,\n",
    "                 max_deletions=20):\n",
    "        self.dim  = dim\n",
    "        self.lam  = lam\n",
    "\n",
    "        # Model parameters & (regularised) Hessian inverse\n",
    "        self.theta = np.zeros(dim)\n",
    "        self.H_inv = np.eye(dim) / lam          # (X·µÄX + ŒªI)‚Åª¬π\n",
    "\n",
    "        # Storage: keep raw (x,y) for exact gradient recomputation\n",
    "        self.data_store = {}     # id -> (x, y)\n",
    "        self.deleted     = set()\n",
    "\n",
    "        # --- privacy bookkeeping ---\n",
    "        self.K          = max_deletions          # anticipate ‚â§K deletions\n",
    "        self.eps_total  = eps_total\n",
    "        self.delta_total = delta_total\n",
    "        self.eps_step   = eps_total  / (2*max_deletions)   # split budget\n",
    "        self.delta_step = delta_total / (2*max_deletions)\n",
    "        self.eps_spent  = 0.0\n",
    "\n",
    "    # 1st-order gradient (current Œ∏)\n",
    "    def grad(self, x, y):\n",
    "        err = self.theta @ x - y\n",
    "        return err * x\n",
    "\n",
    "    # ---------------- insert ----------------\n",
    "    def insert(self, idx, x, y):\n",
    "        \"\"\"Process a new data point (x,y).\"\"\"\n",
    "        if idx in self.deleted or idx in self.data_store:\n",
    "            raise ValueError(\"duplicate id\")\n",
    "\n",
    "        # Update inverse Hessian   H‚Åª¬π ‚Üê (H + x x·µÄ)‚Åª¬π  via Sherman‚ÄìMorrison\n",
    "        self.H_inv = sm_add_inv(self.H_inv, x)\n",
    "\n",
    "        # One Newton step using fresh gradient\n",
    "        g = self.grad(x, y)\n",
    "        self.theta -= self.H_inv @ g\n",
    "\n",
    "        # Store raw data for possible future deletion\n",
    "        self.data_store[idx] = (x, y)\n",
    "\n",
    "    # ---------------- delete ----------------\n",
    "    def delete(self, idx):\n",
    "        \"\"\"Remove the influence of data point idx (if present).\"\"\"\n",
    "        if idx in self.deleted or idx not in self.data_store:\n",
    "            return\n",
    "\n",
    "        x, y = self.data_store.pop(idx)\n",
    "\n",
    "        # ---------------- Hessian downdate ----------------\n",
    "        self.H_inv = sm_remove_inv(self.H_inv, x)\n",
    "\n",
    "        # Re-compute gradient of this point *at current Œ∏*\n",
    "        g = self.grad(x, y)\n",
    "\n",
    "        delta_theta = self.H_inv @ g       # influence to remove\n",
    "        self.theta -= delta_theta\n",
    "\n",
    "        # ---------------- calibrated Gaussian noise ----------------\n",
    "        sensitivity = np.linalg.norm(delta_theta, 2)\n",
    "        sigma = (sensitivity *\n",
    "                 np.sqrt(2*np.log(1.25/self.delta_step))\n",
    "                 / self.eps_step)\n",
    "\n",
    "        self.theta += np.random.normal(0.0, sigma, size=self.dim)\n",
    "\n",
    "        # Budget accounting\n",
    "        self.eps_spent += self.eps_step\n",
    "        self.deleted.add(idx)\n",
    "\n",
    "    # ---------------- utility ----------------\n",
    "    def privacy_ok(self):\n",
    "        return self.eps_spent <= self.eps_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3118ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting 500 simulations...\n",
      "\n",
      "--- ‚úÖ Simulation Analysis ---\n",
      "Ran 500 successful simulations.\n",
      "\n",
      "üìä [RESULTS] Incremental Deletion vs. Retraining\n",
      "The relative error is, on average, 15.17%\n",
      "95% Confidence Interval: [14.40%, 15.94%]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m95% Confidence Interval: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# --- Save results to /results/ directory ---\u001b[39;00m\n\u001b[1;32m     81\u001b[0m results_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m---> 82\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m)),\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     84\u001b[0m )\n\u001b[1;32m     85\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\n\u001b[1;32m     86\u001b[0m     results_dir, \n\u001b[1;32m     87\u001b[0m     exist_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Save errors as .npy\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from memory_pair import MemoryPair\n",
    "import os\n",
    "\n",
    "def generate_synthetic_data(n_samples=1000, n_features=10, noise=0.5):\n",
    "    \"\"\"Generates synthetic data for a linear regression problem.\"\"\"\n",
    "    X = np.random.rand(\n",
    "        n_samples, \n",
    "        n_features\n",
    "    )\n",
    "    true_w = np.random.randn(n_features)\n",
    "    y = X @ true_w + np.random.normal(\n",
    "        0, \n",
    "        noise, \n",
    "        n_samples\n",
    "    )\n",
    "    return list(zip(X, y))\n",
    "\n",
    "def run_single_simulation(seed: int):\n",
    "    \"\"\"Runs one full simulation and returns the error metrics.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    N_INITIAL_TRAIN, N_FEATURES, N_DELETE, ALPHA = 4500, 5, 500, 0.1\n",
    "    data = generate_synthetic_data(\n",
    "        n_samples = N_INITIAL_TRAIN, \n",
    "        n_features = N_FEATURES\n",
    "    )\n",
    "    initial_data, data_to_delete = data[:-N_DELETE], data[-N_DELETE:]\n",
    "    \n",
    "    loss = lambda w, z: 0.5 * (z[0] @ w - z[1])**2 + 0.5 * ALPHA * np.dot(w, w)\n",
    "    grad = lambda w, z: (z[0] @ w - z[1]) * z[0] + ALPHA * w\n",
    "    hess = lambda w, z: np.outer(z[0], z[0]) + ALPHA * np.identity(N_FEATURES)\n",
    "    \n",
    "    model = MemoryPair(\n",
    "        d = N_FEATURES, \n",
    "        loss = loss, \n",
    "        grad = grad, \n",
    "        hess = hess, \n",
    "        lam = ALPHA\n",
    "    )\n",
    "    model.fit(initial_data)\n",
    "    model.delete(data_to_delete)\n",
    "    w_deleted_approx = model.w.copy()\n",
    "\n",
    "    data_after_delete = initial_data[:-N_DELETE]\n",
    "    model_retrained = MemoryPair(\n",
    "        d = N_FEATURES, \n",
    "        loss = loss, \n",
    "        grad = grad, \n",
    "        hess = hess, \n",
    "        lam = ALPHA\n",
    "    )\n",
    "    model_retrained.fit(data_after_delete)\n",
    "    w_deleted_retrained = model_retrained.w.copy()\n",
    "    \n",
    "    error = np.linalg.norm(w_deleted_approx - w_deleted_retrained)\n",
    "    norm = np.linalg.norm(w_deleted_retrained)\n",
    "    return (error / norm) * 100 if norm != 0 else 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N_SIMULATIONS = 500\n",
    "    print(f\"üöÄ Starting {N_SIMULATIONS} simulations...\")\n",
    "\n",
    "    errors = [run_single_simulation(seed=i) for i in range(N_SIMULATIONS)]\n",
    "\n",
    "    mean_error = np.mean(errors)\n",
    "    ci = st.t.interval(\n",
    "        0.95,\n",
    "        len(errors)-1,\n",
    "        loc=mean_error,\n",
    "        scale=st.sem(errors)\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- ‚úÖ Simulation Analysis ---\")\n",
    "    print(f\"Ran {len(errors)} successful simulations.\")\n",
    "    print(\"\\nüìä [RESULTS] Incremental Deletion vs. Retraining\")\n",
    "    print(f\"The relative error is, on average, {mean_error:.2f}%\")\n",
    "    print(f\"95% Confidence Interval: [{ci[0]:.2f}%, {ci[1]:.2f}%]\")\n",
    "\n",
    "    # --- Save results to /results/ directory ---\n",
    "    results_dir = os.path.join(\n",
    "        os.path.dirname(os.path.dirname(__file__)),\n",
    "        'results'\n",
    "    )\n",
    "    os.makedirs(\n",
    "        results_dir, \n",
    "        exist_ok = True\n",
    "        )\n",
    "\n",
    "    # Save errors as .npy\n",
    "    np.save(\n",
    "        os.path.join(\n",
    "            results_dir, \n",
    "            'errors.npy'\n",
    "        ), \n",
    "        np.array(errors)\n",
    "    )\n",
    "\n",
    "    # Save summary statistics as .txt\n",
    "    summary_path = os.path.join(\n",
    "        results_dir, \n",
    "        'summary.txt'\n",
    "    )\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"--- Simulation Analysis ---\\n\")\n",
    "        f.write(f\"Ran {len(errors)} successful simulations.\\n\")\n",
    "        f.write(\"[RESULTS] Incremental Deletion vs. Retraining\\n\")\n",
    "        f.write(f\"The relative error is, on average, {mean_error:.2f}%\\n\")\n",
    "        f.write(f\"95% Confidence Interval: [{ci[0]:.2f}%, {ci[1]:.2f}%]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fff0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
